{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad23b834",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = os.getenv('HOME')+'/aiffel/conditional_generation/data/pokemon_pix2pix_dataset/train/'\n",
    "print(\"number of train examples :\", len(os.listdir(data_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae842fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "for i in range(1, 7):\n",
    "    f = data_path + os.listdir(data_path)[np.random.randint(800)]\n",
    "    img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "    plt.subplot(3,2,i)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1189a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = data_path + os.listdir(data_path)[0]\n",
    "img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f1ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def normalize(x):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    return (x/127.5) - 1\n",
    "\n",
    "def denormalize(x):\n",
    "    x = (x+1)*127.5\n",
    "    x = x.numpy()\n",
    "    return x.astype(np.uint8)\n",
    "\n",
    "def load_img(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_image(img, 3)\n",
    "    \n",
    "    w = tf.shape(img)[1] // 2\n",
    "    sketch = img[:, :w, :] \n",
    "    sketch = tf.cast(sketch, tf.float32)\n",
    "    colored = img[:, w:, :] \n",
    "    colored = tf.cast(colored, tf.float32)\n",
    "    return normalize(sketch), normalize(colored)\n",
    "\n",
    "f = data_path + os.listdir(data_path)[1]\n",
    "sketch, colored = load_img(f)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.subplot(1,2,1); plt.imshow(denormalize(sketch))\n",
    "plt.subplot(1,2,2); plt.imshow(denormalize(colored))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import image\n",
    "from tensorflow.keras.preprocessing.image import random_rotation\n",
    "\n",
    "@tf.function() # 빠른 텐서플로 연산을 위해 @tf.function()을 사용합니다. \n",
    "def apply_augmentation(sketch, colored):\n",
    "    stacked = tf.concat([sketch, colored], axis=-1)\n",
    "    \n",
    "    _pad = tf.constant([[30,30],[30,30],[0,0]])\n",
    "    if tf.random.uniform(()) < .5:\n",
    "        padded = tf.pad(stacked, _pad, \"REFLECT\")\n",
    "    else:\n",
    "        padded = tf.pad(stacked, _pad, \"CONSTANT\", constant_values=1.)\n",
    "\n",
    "    out = image.random_crop(padded, size=[256, 256, 6])\n",
    "    \n",
    "    out = image.random_flip_left_right(out)\n",
    "    out = image.random_flip_up_down(out)\n",
    "    \n",
    "    if tf.random.uniform(()) < .5:\n",
    "        degree = tf.random.uniform([], minval=1, maxval=4, dtype=tf.int32)\n",
    "        out = image.rot90(out, k=degree)\n",
    "    \n",
    "    return out[...,:3], out[...,3:]   \n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10047e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,13))\n",
    "img_n = 1\n",
    "for i in range(1, 13, 2):\n",
    "    augmented_sketch, augmented_colored = apply_augmentation(sketch, colored)\n",
    "    \n",
    "    plt.subplot(3,4,i)\n",
    "    plt.imshow(denormalize(augmented_sketch)); plt.title(f\"Image {img_n}\")\n",
    "    plt.subplot(3,4,i+1); \n",
    "    plt.imshow(denormalize(augmented_colored)); plt.title(f\"Image {img_n}\")\n",
    "    img_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e249f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import data\n",
    "\n",
    "def get_train(img_path):\n",
    "    sketch, colored = load_img(img_path)\n",
    "    sketch, colored = apply_augmentation(sketch, colored)\n",
    "    return sketch, colored\n",
    "\n",
    "train_images = data.Dataset.list_files(data_path + \"*.jpg\")\n",
    "train_images = train_images.map(get_train).shuffle(100).batch(4)\n",
    "\n",
    "sample = train_images.take(1)\n",
    "sample = list(sample.as_numpy_iterator())\n",
    "sketch, colored = (sample[0][0]+1)*127.5, (sample[0][1]+1)*127.5\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1); plt.imshow(sketch[0].astype(np.uint8))\n",
    "plt.subplot(1,2,2); plt.imshow(colored[0].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45351262",
   "metadata": {},
   "source": [
    "## 2. Generator 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Input, Model\n",
    "\n",
    "class EncodeBlock(layers.Layer):\n",
    "    def __init__(self, n_filters, use_bn=True):\n",
    "        super(EncodeBlock, self).__init__()\n",
    "        self.use_bn = use_bn       \n",
    "        self.conv = layers.Conv2D(n_filters, 4, 2, \"same\", use_bias=False)\n",
    "        self.batchnorm = layers.BatchNormalization()\n",
    "        self.lrelu= layers.LeakyReLU(0.2)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        return self.lrelu(x)\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdeaae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        filters = [64,128,256,512,512,512,512,512]\n",
    "        \n",
    "        # for문과 리스트 filter를 활용해서 EncoderBlock을 쌓아주세요.\n",
    "        # 조건 1. 첫번째 EncoderBlock의 경우 Batch Normalization을 생략해주세요.\n",
    "        self.blocks = []\n",
    "        for i, f in enumerate(filters):\n",
    "            if i == 0:\n",
    "                self.blocks.append(EncodeBlock(f, use_bn=False))\n",
    "            else:\n",
    "                self.blocks.append(EncodeBlock(f))\n",
    "    \n",
    "    def call(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n",
    "    \n",
    "    def get_summary(self, input_shape=(256,256,3)):\n",
    "        inputs = Input(input_shape)\n",
    "        return Model(inputs, self.call(inputs)).summary()\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder().get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969e43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeBlock(layers.Layer):\n",
    "    def __init__(self, f, dropout=True):\n",
    "        super(DecodeBlock, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.Transconv = layers.Conv2DTranspose(f, 4, 2, \"same\", use_bias=False)\n",
    "        self.batchnorm = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.Transconv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        if self.dropout:\n",
    "            x = layers.Dropout(.5)(x)\n",
    "        return self.relu(x)\n",
    "\n",
    "    \n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        filters = [512,512,512,512,256,128,64]\n",
    "        # for문을 이용해서 모델을 쌓아주세요.\n",
    "        # 조건 1. 3번째 block까지는 Dropout을 사용하되 그 이후에는 Dropout을 사용하지 마세요.\n",
    "        # for문이 끝난 다음 Conv2DTranspose를 쌓아주되 output 차원수는 3, filter 사이즈는 4, stride는 2로 구성해주시고 자동 패딩 적용해주시되 bias는 사용하지 않습니다.\n",
    "        self.blocks = []\n",
    "        for i, f in enumerate(filters):\n",
    "            if i < 3:\n",
    "                self.blocks.append(DecodeBlock(f))\n",
    "            else:\n",
    "                self.blocks.append(DecodeBlock(f, dropout=False))\n",
    "                \n",
    "        self.blocks.append(layers.Conv2DTranspose(3, 4, 2, \"same\", use_bias=False))\n",
    "        \n",
    "    def call(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n",
    "            \n",
    "    def get_summary(self, input_shape=(1,1,512)):\n",
    "        inputs = Input(input_shape)\n",
    "        return Model(inputs, self.call(inputs)).summary()\n",
    "        \n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c30ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decoder().get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad70f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderGenerator(Model):\n",
    "    def __init__(self):\n",
    "        super(EncoderDecoderGenerator, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "   \n",
    "    def get_summary(self, input_shape=(256,256,3)):\n",
    "        inputs = Input(input_shape)\n",
    "        return Model(inputs, self.call(inputs)).summary()\n",
    "        \n",
    "\n",
    "EncoderDecoderGenerator().get_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c811e64",
   "metadata": {},
   "source": [
    "## 3. Generator 재구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0450024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeBlock(layers.Layer):\n",
    "    def __init__(self, n_filters, use_bn=True):\n",
    "        super(EncodeBlock, self).__init__()\n",
    "        self.use_bn = use_bn       \n",
    "        self.conv = layers.Conv2D(n_filters, 4, 2, \"same\", use_bias=False)\n",
    "        self.batchnorm = layers.BatchNormalization()\n",
    "        self.lrelu = layers.LeakyReLU(0.2)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        return self.lrelu(x)\n",
    "\n",
    "    \n",
    "class DecodeBlock(layers.Layer):\n",
    "    def __init__(self, f, dropout=True):\n",
    "        super(DecodeBlock, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.Transconv = layers.Conv2DTranspose(f, 4, 2, \"same\", use_bias=False)\n",
    "        self.batchnorm = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.Transconv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        if self.dropout:\n",
    "            x = layers.Dropout(.5)(x)\n",
    "        return self.relu(x)\n",
    "    \n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetGenerator(Model):\n",
    "    def __init__(self):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "        encode_filters = [64,128,256,512,512,512,512,512]\n",
    "        decode_filters = [512,512,512,512,256,128,64]\n",
    "        \n",
    "        self.encode_blocks = []\n",
    "        for i, f in enumerate(encode_filters):\n",
    "            if i == 0:\n",
    "                self.encode_blocks.append(EncodeBlock(f, use_bn=False))\n",
    "            else:\n",
    "                self.encode_blocks.append(EncodeBlock(f))\n",
    "        \n",
    "        self.decode_blocks = []\n",
    "        for i, f in enumerate(decode_filters):\n",
    "            if i < 3:\n",
    "                self.decode_blocks.append(DecodeBlock(f))\n",
    "            else:\n",
    "                self.decode_blocks.append(DecodeBlock(f, dropout=False))\n",
    "        \n",
    "        self.last_conv = layers.Conv2DTranspose(3, 4, 2, \"same\", use_bias=False)\n",
    "    \n",
    "    def call(self, x):\n",
    "        features = []\n",
    "        for block in self.encode_blocks:\n",
    "            x = block(x)\n",
    "            features.append(x)\n",
    "        \n",
    "        features = features[:-1]\n",
    "                    \n",
    "        for block, feat in zip(self.decode_blocks, features[::-1]):\n",
    "            x = block(x)\n",
    "            x = layers.Concatenate()([x, feat])\n",
    "        \n",
    "        x = self.last_conv(x)\n",
    "        return x\n",
    "                \n",
    "    def get_summary(self, input_shape=(256,256,3)):\n",
    "        inputs = Input(input_shape)\n",
    "        return Model(inputs, self.call(inputs)).summary()\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42076a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNetGenerator().get_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2e0099",
   "metadata": {},
   "source": [
    "## 4. Discriminator 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcaf678",
   "metadata": {},
   "source": [
    "### Discriminator 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4876795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscBlock(layers.Layer):\n",
    "    def __init__(self, n_filters, stride=2, custom_pad=False, use_bn=True, act=True):\n",
    "        super(DiscBlock, self).__init__()\n",
    "        self.custom_pad = custom_pad\n",
    "        self.use_bn = use_bn\n",
    "        self.act = act\n",
    "        \n",
    "        if custom_pad:\n",
    "            self.padding = layers.ZeroPadding2D()\n",
    "            self.conv = layers.Conv2D(n_filters, 4, stride, \"valid\", use_bias=False)\n",
    "        else:\n",
    "            self.conv = layers.Conv2D(n_filters, 4, stride, \"same\", use_bias=False)\n",
    "        \n",
    "        self.batchnorm = layers.BatchNormalization() if use_bn else None\n",
    "        self.lrelu = layers.LeakyReLU(0.2) if act else None\n",
    "        \n",
    "    def call(self, x):\n",
    "        if self.custom_pad:\n",
    "            x = self.padding(x)\n",
    "            x = self.conv(x)\n",
    "        else:\n",
    "            x = self.conv(x)\n",
    "                \n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "            \n",
    "        if self.act:\n",
    "            x = self.lrelu(x)\n",
    "        return x \n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        filters = [64,128,256,512,1]\n",
    "        self.blocks = [layers.Concatenate()]\n",
    "        # For문을 활용해서 DiscBlock을 쌓아주세요.\n",
    "        # 조건 1 : 3번째까지 stride는 2로 주되 이후에는 1로 주세요\n",
    "        # 조건 2 : 3번째까지 custom padding을 주지 않아도 되는데 이후에는 주세요.\n",
    "        # 조건 3: 1번째와 5번째에서는 Batch Normalization을 사용하지 마세요.\n",
    "        # 조건 4 : 1번째부터 4번째까지 LeakyReLU를 적용하고 마지막에는 sigmoid를 적용하세요. (sigmoid의 경우 따로 정의해야 합니다)\n",
    "        for i, f in enumerate(filters):\n",
    "            self.blocks.append(\n",
    "                DiscBlock(\n",
    "                    n_filters=f,\n",
    "                    stride=2 if i < 3 else 1,\n",
    "                    custom_pad=False if i < 3 else True,\n",
    "                    use_bn=False if i==0 and i==4 else True,\n",
    "                    act=True if i < 4 else False\n",
    "            ))\n",
    "        self.sigmoid = layers.Activation(activation='sigmoid')\n",
    "        \n",
    "    \n",
    "    def call(self, x, y):\n",
    "        out = self.blocks[0]([x, y])\n",
    "        out = self.blocks[1](out)\n",
    "        out = self.blocks[2](out)\n",
    "        out = self.blocks[3](out)\n",
    "        out = self.blocks[4](out)\n",
    "        out = self.blocks[5](out)\n",
    "        return self.sigmoid(out)\n",
    "    \n",
    "    def get_summary(self, x_shape=(256,256,3), y_shape=(256,256,3)):\n",
    "        x, y = Input(x_shape), Input(y_shape) \n",
    "        return Model((x, y), self.call(x, y)).summary()\n",
    "    \n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a2244e",
   "metadata": {},
   "source": [
    "## 5. 학습 및 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19fa360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import losses\n",
    "\n",
    "bce = losses.BinaryCrossentropy(from_logits=False)\n",
    "mae = losses.MeanAbsoluteError()\n",
    "\n",
    "def get_gene_loss(fake_output, real_output, fake_disc):\n",
    "    l1_loss = mae(real_output, fake_output)\n",
    "    gene_loss = bce(tf.ones_like(fake_disc), fake_disc)\n",
    "    return gene_loss, l1_loss\n",
    "\n",
    "def get_disc_loss(fake_disc, real_disc):\n",
    "    return bce(tf.zeros_like(fake_disc), fake_disc) + bce(tf.ones_like(real_disc), real_disc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "gene_opt = optimizers.Adam(2e-4, beta_1=.5, beta_2=.999)\n",
    "disc_opt = optimizers.Adam(2e-4, beta_1=.5, beta_2=.999)\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(sketch, real_colored):\n",
    "    with tf.GradientTape() as gene_tape, tf.GradientTape() as disc_tape:\n",
    "    # 이전에 배웠던 내용을 토대로 train_step을 구성해주세요.\n",
    "        # Generator 예측\n",
    "        fake_colored = generator(sketch, training=True)\n",
    "        # Discriminator 예측\n",
    "        fake_disc = discriminator(sketch, fake_colored, training=True)\n",
    "        real_disc = discriminator(sketch, real_colored, training=True)\n",
    "        # Generator 손실 계산\n",
    "        gene_loss, l1_loss = get_gene_loss(fake_colored, real_colored, fake_disc)\n",
    "        gene_total_loss = gene_loss + (100 * l1_loss) # L1 손실 반영 lambda=100\n",
    "        # Discrminator 손실 계산\n",
    "        disc_loss = get_disc_loss(fake_disc, real_disc)\n",
    "\n",
    "    gene_gradient = gene_tape.gradient(gene_total_loss, generator.trainable_variables)\n",
    "    disc_gradient = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    gene_opt.apply_gradients(zip(gene_gradient, generator.trainable_variables))\n",
    "    disc_opt.apply_gradients(zip(disc_gradient, discriminator.trainable_variables))\n",
    "    return gene_loss, l1_loss, disc_loss\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48cad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "generator = UNetGenerator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    for i, (sketch, colored) in enumerate(train_images):\n",
    "        g_loss, l1_loss, d_loss = train_step(sketch, colored)\n",
    "                \n",
    "        # 10회 반복마다 손실을 출력합니다.\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"EPOCH[{epoch}] - STEP[{i+1}] \\\n",
    "                    \\nGenerator_loss:{g_loss.numpy():.4f} \\\n",
    "                    \\nL1_loss:{l1_loss.numpy():.4f} \\\n",
    "                    \\nDiscriminator_loss:{d_loss.numpy():.4f}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind = 1\n",
    "\n",
    "f = data_path + os.listdir(data_path)[test_ind]\n",
    "sketch, colored = load_img(f)\n",
    "\n",
    "pred = generator(tf.expand_dims(sketch, 0))\n",
    "pred = denormalize(pred)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,3,1); plt.imshow(denormalize(sketch))\n",
    "plt.subplot(1,3,2); plt.imshow(pred[0])\n",
    "plt.subplot(1,3,3); plt.imshow(denormalize(colored))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41dee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
